version: "3.8"
services:
  postgres:
    image: postgres:15
    container_name: citi_postgres
    restart: always
    command:
      - "postgres"
      - "-c"
      - "shared_buffers=256MB"
      - "-c"
      - "work_mem=16MB"
      - "-c"
      - "maintenance_work_mem=64MB"
      - "-c"
      - "effective_cache_size=512MB"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: citi
    ports:
      - "5433:5432"
    volumes:
      - ./data/postgres_data:/var/lib/postgresql/data


  webserver:
    image: apache/airflow:2.9.0
    container_name: citi_airflow_web
    restart: always
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__EXECUTOR: "LocalExecutor"
      AIRFLOW__CORE__FERNET_KEY: "DuDgykhP2svGLuSIgREwRa-8Co-__syLwu3WT4_YL5k="
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://postgres:postgres@postgres:5432/citi"
      AIRFLOW__WEBSERVER__WEB_SERVER_HOST: "0.0.0.0"
      AIRFLOW__WEBSERVER__WEB_SERVER_PORT: "8080"
      AIRFLOW__WEBSERVER__SECRET_KEY: a9491c7d3a13e05110164f44ca254ef683b3b5c54e392e2f7e1342d237a719a0
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: citi
      DB_CONN: postgresql+psycopg2://postgres:postgres@postgres:5432/citi
      PYTHONPATH: /opt/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
    ports:
      - "8080:8080"
    command: >
      bash -lc "
        airflow db migrate &&
        airflow users create --username admin --password admin --firstname Air --lastname Flow --role Admin --email admin@airflow.com || true &&
        exec airflow webserver
      "

  scheduler:
    image: apache/airflow:2.9.0
    container_name: citi_airflow_sched
    restart: always
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__EXECUTOR: "LocalExecutor"
      AIRFLOW__CORE__FERNET_KEY: "DuDgykhP2svGLuSIgREwRa-8Co-__syLwu3WT4_YL5k="
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://postgres:postgres@postgres:5432/citi"
      AIRFLOW__WEBSERVER__SECRET_KEY: a9491c7d3a13e05110164f44ca254ef683b3b5c54e392e2f7e1342d237a719a0
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: citi
      DB_CONN: postgresql+psycopg2://postgres:postgres@postgres:5432/citi
      PYTHONPATH: /opt/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
    command: "airflow scheduler"


  dbt:
    platform: linux/amd64
    image: ghcr.io/dbt-labs/dbt-postgres:1.8.2 #Cette image a déjà dbt par defaut
    container_name: citi_dbt
    depends_on:
      - postgres #dbt ne se lancera qu’après que le conteneur Postgres soit démarré.
    environment:
      DBT_PROFILES_DIR: /opt/dbt/profiles   #Définit la variable d’environnement pour que dbt sache où trouver profiles.yml.
    volumes:
      - ./dbt:/opt/dbt                      #Monte ton dossier local ./dbt (où tu as ton projet dbt, y compris dbt_project.yml et profiles.yml) dans le conteneur à l’emplacement /opt/dbt.
    working_dir: /opt/dbt
    command: build --target prod

    #installe les dépendances (si déjà présentes dans packages.yml),
    #exécute tous les modèles (staging+ vault +marts+ par défaut si rien n’est filtré),
    #utilise la cible prod dans ton profiles.yml.

volumes:
  citi_pgdata:
